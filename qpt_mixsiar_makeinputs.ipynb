{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QPT MixSIAR\n",
    "Create MixSIAR input files\n",
    "\n",
    "**Manuscript title**: Bayesian modeling of plant wax sources to an Eastern Canadian Arctic lake sediment record reveals stable plant wax vegetation sources following postglacial shrub colonization\n",
    "\n",
    "**Manuscript authors**: Kurt R. Lindberg, Elizabeth K. Thomas, Martha K. Raynolds, Helga Bultmann\n",
    "\n",
    "**DOI**\": pending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "## Import necessary Python packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Function that generates MixSIAR source input files\n",
    "\n",
    "def make_source(sources, source_names, data_type, start_chain, end_chain, scale):\n",
    "\n",
    "  conc_data_type = data_type + \"conc\"\n",
    "  iso_data_type = data_type + \"d13c\"\n",
    "  chain_lengths = list(range(start_chain, end_chain+1))\n",
    "  source_n = []\n",
    "  tracers = {}\n",
    "\n",
    "  names = pd.Series(data=source_names, name='source_names')\n",
    "\n",
    "  for i in range(0, len(sources['Endmember'])):\n",
    "    source_n.append(len(sources['Endmember'][i].growth_form))\n",
    "\n",
    "  n_samples = pd.DataFrame(data=np.array(source_n), columns=['n'])\n",
    "\n",
    "  match data_type:\n",
    "    case \"f\":\n",
    "        chain_lengths = [num for num in chain_lengths if num % 2 == 0]\n",
    "    case \"a\":\n",
    "        chain_lengths = [num for num in chain_lengths if num % 2 == 1]\n",
    "\n",
    "  for n in chain_lengths:\n",
    "    tracers.update(\n",
    "        {\n",
    "          f\"Meanc{n}\": [],\n",
    "          f\"SDc{n}\": [],\n",
    "          f\"Concc{n}\": []\n",
    "        }\n",
    "      )\n",
    "\n",
    "    for end in range(0, len(sources['Endmember'])):\n",
    "      df = sources['Endmember'][end]\n",
    "      wax_conc_all = df.filter(regex=conc_data_type)\n",
    "      wax_iso_all = df.filter(regex=iso_data_type)\n",
    "\n",
    "      chain_conc = pd.DataFrame(data=np.array(wax_conc_all.filter(items=[\"c\"+str(n)+\"_\"+conc_data_type])), columns=[str(n)])\n",
    "      chain_iso = pd.DataFrame(data=np.array(wax_iso_all.filter(items=[\"c\"+str(n)+\"_\"+iso_data_type])), columns=[str(n)])\n",
    "\n",
    "      tracers[f\"Meanc{n}\"].append(np.nanmean(np.array(chain_iso)))\n",
    "      tracers[f\"SDc{n}\"].append(np.nanstd(np.array(chain_iso)))\n",
    "      tracers[f\"Concc{n}\"].append((np.nanmean(np.array(chain_conc)))*scale[end])\n",
    "\n",
    "  mixsiar_tracers = pd.DataFrame(data=tracers)\n",
    "  mixsiar_source = pd.concat([names, mixsiar_tracers, n_samples], axis=1)\n",
    "\n",
    "  return mixsiar_source\n",
    "\n",
    "\n",
    "# Function that generates MixSIAR discrimination factor (discr) input files\n",
    "\n",
    "def make_discr(source_names, data_type, start_chain, end_chain):\n",
    "\n",
    "  tracers = {}\n",
    "  names = pd.Series(data=source_names, name='source_names')\n",
    "  chain_lengths = list(range(start_chain, end_chain+1))\n",
    "\n",
    "  match data_type:\n",
    "    case \"f\":\n",
    "        chain_lengths = [num for num in chain_lengths if num % 2 == 0]\n",
    "    case \"a\":\n",
    "        chain_lengths = [num for num in chain_lengths if num % 2 == 1]\n",
    "\n",
    "  for n in chain_lengths:\n",
    "    tracers.update(\n",
    "      {\n",
    "        f\"Meanc{n}\": np.zeros(len(source_names)),\n",
    "        f\"SDc{n}\": np.zeros(len(source_names))\n",
    "      }\n",
    "    )\n",
    "\n",
    "  mixsiar_tracers = pd.DataFrame(data=tracers)\n",
    "  mixsiar_discr = pd.concat([names, mixsiar_tracers], axis=1)\n",
    "\n",
    "  return mixsiar_discr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "## Import raw plant wax data for endmember priors\n",
    "\n",
    "# Lake QPT data only - Hollister et al. (2022)\n",
    "# DOI: \n",
    "wax_data = pd.read_excel(\n",
    "    'qpt_plantwax_source.xlsx',\n",
    "    sheet_name='plantwax'\n",
    ")\n",
    "\n",
    "# Remove samples where concentration is not reported in ug/g plant\n",
    "wax_data = wax_data[wax_data['conc_ugg_plant'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "## Define endmember groupings\n",
    "\n",
    "# All terrestrial plants\n",
    "terr = wax_data[wax_data['habitat'] == 'terrestrial'].reset_index(drop=True)\n",
    "\n",
    "# Terrestrial vascular plants\n",
    "tvas = terr[terr['growth_form'].str.contains(\"tree|shrub|forb|fern|graminoid\")].reset_index(drop=True)\n",
    "\n",
    "# Terrestrial shrubs\n",
    "tshr = tvas[tvas['growth_form'] == 'shrub'].reset_index(drop=True)\n",
    "\n",
    "# Terrestrial non-shrubs\n",
    "tnshr = tvas[tvas['growth_form'] != 'shrub'].reset_index(drop=True)\n",
    "\n",
    "# Terrestrial non-vascular plants\n",
    "tnvas = terr[terr['growth_form'].str.contains(\"moss|liverwort|lichen\")].reset_index(drop=True)\n",
    "\n",
    "# All aquatic plants\n",
    "aqua = wax_data[wax_data['habitat'] != 'terrestrial'].reset_index(drop=True)\n",
    "\n",
    "# Aquatic non-vascular plants\n",
    "anvas = aqua[aqua['growth_form'].str.contains(\"moss|algae\")].reset_index(drop=True)\n",
    "\n",
    "# Aquatic vascular plants\n",
    "avas = aqua[aqua['growth_form'].str.contains(\"forb|graminoid\")].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "## Generate QPT-only MixSIAR source files\n",
    "\n",
    "source_qpt_4end_c22c28 = make_source(\n",
    "  sources={\n",
    "    'Endmember': [\n",
    "      aqua,\n",
    "      tnvas,\n",
    "      tnshr,\n",
    "      tshr\n",
    "    ]\n",
    "  },\n",
    "  source_names=['aqua','nonvas','nonshrub','shrub'],\n",
    "  data_type=\"f\",\n",
    "  start_chain=22,\n",
    "  end_chain=28,\n",
    "  scale=[1,1,1,1]\n",
    ").to_csv('source/source_qpt_4end_c22c28.csv', index=False)\n",
    "\n",
    "source_qpt_3end_c22c28 = make_source(\n",
    "  sources={\n",
    "    'Endmember': [\n",
    "    aqua,\n",
    "    tnvas,\n",
    "    tvas\n",
    "    ]\n",
    "  },\n",
    "  source_names=['aqua','nonvas','tvas'],\n",
    "  data_type=\"f\",\n",
    "  start_chain=22,\n",
    "  end_chain=28,\n",
    "  scale=[1,1,1]\n",
    ").to_csv('source/source_qpt_3end_c22c28.csv', index=False)\n",
    "\n",
    "source_qpt_3end_c22c24 = make_source(\n",
    "  sources={\n",
    "    'Endmember': [\n",
    "    aqua,\n",
    "    tnvas,\n",
    "    tvas\n",
    "    ]\n",
    "  },\n",
    "  source_names=['aqua','nonvas','tvas'],\n",
    "  data_type=\"f\",\n",
    "  start_chain=22,\n",
    "  end_chain=24,\n",
    "  scale=[1,1,1]\n",
    ").to_csv('source/source_qpt_3end_c22c24.csv', index=False)\n",
    "\n",
    "source_qpt_3end_c26c28 = make_source(\n",
    "  sources={\n",
    "    'Endmember': [\n",
    "    aqua,\n",
    "    tnvas,\n",
    "    tvas\n",
    "    ]\n",
    "  },\n",
    "  source_names=['aqua','nonvas','tvas'],\n",
    "  data_type=\"f\",\n",
    "  start_chain=26,\n",
    "  end_chain=28,\n",
    "  scale=[1,1,1]\n",
    ").to_csv('source/source_qpt_3end_c26c28.csv', index=False)\n",
    "\n",
    "\n",
    "source_qpt_2end_c22c28 = make_source(\n",
    "  sources={\n",
    "    'Endmember': [\n",
    "      aqua,\n",
    "      terr\n",
    "    ]\n",
    "  },\n",
    "  source_names=['aqua','terr'],\n",
    "  data_type=\"f\",\n",
    "  start_chain=22,\n",
    "  end_chain=28,\n",
    "  scale=[1,1]\n",
    ").to_csv('source/source_qpt_2end_c22c28.csv', index=False)\n",
    "\n",
    "source_qpt_2end_c22c24 = make_source(\n",
    "  sources={\n",
    "    'Endmember': [\n",
    "      aqua,\n",
    "      terr\n",
    "    ]\n",
    "  },\n",
    "  source_names=['aqua','terr'],\n",
    "  data_type=\"f\",\n",
    "  start_chain=22,\n",
    "  end_chain=24,\n",
    "  scale=[1,1]\n",
    ").to_csv('source/source_qpt_2end_c22c24.csv', index=False)\n",
    "\n",
    "source_qpt_2end_c26c28 = make_source(\n",
    "  sources={\n",
    "    'Endmember': [\n",
    "      aqua,\n",
    "      terr\n",
    "    ]\n",
    "  },\n",
    "  source_names=['aqua','terr'],\n",
    "  data_type=\"f\",\n",
    "  start_chain=26,\n",
    "  end_chain=28,\n",
    "  scale=[1,1]\n",
    ").to_csv('source/source_qpt_2end_c26c28.csv', index=False)\n",
    "\n",
    "source_qpt_2end_c22 = make_source(\n",
    "  sources={\n",
    "    'Endmember': [\n",
    "      aqua,\n",
    "      terr\n",
    "    ]\n",
    "  },\n",
    "  source_names=['aqua','terr'],\n",
    "  data_type=\"f\",\n",
    "  start_chain=22,\n",
    "  end_chain=22,\n",
    "  scale=[1,1]\n",
    ").to_csv('source/source_qpt_2end_c22.csv', index=False)\n",
    "\n",
    "source_qpt_2end_c24 = make_source(\n",
    "  sources={\n",
    "    'Endmember': [\n",
    "      aqua,\n",
    "      terr\n",
    "    ]\n",
    "  },\n",
    "  source_names=['aqua','terr'],\n",
    "  data_type=\"f\",\n",
    "  start_chain=24,\n",
    "  end_chain=24,\n",
    "  scale=[1,1]\n",
    ").to_csv('source/source_qpt_2end_c24.csv', index=False)\n",
    "\n",
    "source_qpt_2end_c26 = make_source(\n",
    "  sources={\n",
    "    'Endmember': [\n",
    "      aqua,\n",
    "      terr\n",
    "    ]\n",
    "  },\n",
    "  source_names=['aqua','terr'],\n",
    "  data_type=\"f\",\n",
    "  start_chain=26,\n",
    "  end_chain=26,\n",
    "  scale=[1,1]\n",
    ").to_csv('source/source_qpt_2end_c26.csv', index=False)\n",
    "\n",
    "source_qpt_2end_c28 = make_source(\n",
    "  sources={\n",
    "    'Endmember': [\n",
    "      aqua,\n",
    "      terr\n",
    "    ]\n",
    "  },\n",
    "  source_names=['aqua','terr'],\n",
    "  data_type=\"f\",\n",
    "  start_chain=28,\n",
    "  end_chain=28,\n",
    "  scale=[1,1]\n",
    ").to_csv('source/source_qpt_2end_c28.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "## Generate ECA MixSIAR source files\n",
    "# To be released"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "## Generate discr files\n",
    "# Independent of data selection, endmember types just need to match\n",
    "\n",
    "discr_4end_c22c28 = make_discr(\n",
    "  source_names=['aqua','nonvas','nonshrub','shrub'],\n",
    "  data_type=\"f\",\n",
    "  start_chain=22,\n",
    "  end_chain=28\n",
    ").to_csv('discr/discr_4end_c22c28.csv', index=False)\n",
    "\n",
    "\n",
    "discr_3end_c22c28 = make_discr(\n",
    "  source_names=['aqua','nonvas','tvas'],\n",
    "  data_type=\"f\",\n",
    "  start_chain=22,\n",
    "  end_chain=28\n",
    ").to_csv('discr/discr_3end_c22c28.csv', index=False)\n",
    "\n",
    "discr_3end_c22c24 = make_discr(\n",
    "  source_names=['aqua','nonvas','tvas'],\n",
    "  data_type=\"f\",\n",
    "  start_chain=22,\n",
    "  end_chain=24\n",
    ").to_csv('discr/discr_3end_c22c24.csv', index=False)\n",
    "\n",
    "discr_3end_c26c28 = make_discr(\n",
    "  source_names=['aqua','nonvas','tvas'],\n",
    "  data_type=\"f\",\n",
    "  start_chain=26,\n",
    "  end_chain=28\n",
    ").to_csv('discr/discr_3end_c26c28.csv', index=False)\n",
    "\n",
    "\n",
    "discr_2end_c22c28 = make_discr(\n",
    "  source_names=['aqua','terr'],\n",
    "  data_type=\"f\",\n",
    "  start_chain=22,\n",
    "  end_chain=28\n",
    ").to_csv('discr/discr_2end_c22c28.csv', index=False)\n",
    "\n",
    "discr_2end_c22c24 = make_discr(\n",
    "  source_names=['aqua','terr'],\n",
    "  data_type=\"f\",\n",
    "  start_chain=22,\n",
    "  end_chain=24\n",
    ").to_csv('discr/discr_2end_c22c24.csv', index=False)\n",
    "\n",
    "discr_2end_c26c28 = make_discr(\n",
    "  source_names=['aqua','terr'],\n",
    "  data_type=\"f\",\n",
    "  start_chain=26,\n",
    "  end_chain=28\n",
    ").to_csv('discr/discr_2end_c26c28.csv', index=False)\n",
    "\n",
    "\n",
    "discr_2end_c22 = make_discr(\n",
    "  source_names=['aqua','terr'],\n",
    "  data_type=\"f\",\n",
    "  start_chain=22,\n",
    "  end_chain=22\n",
    ").to_csv('discr/discr_2end_c22.csv', index=False)\n",
    "\n",
    "discr_2end_c24 = make_discr(\n",
    "  source_names=['aqua','terr'],\n",
    "  data_type=\"f\",\n",
    "  start_chain=24,\n",
    "  end_chain=24\n",
    ").to_csv('discr/discr_2end_c24.csv', index=False)\n",
    "\n",
    "discr_2end_c26 = make_discr(\n",
    "  source_names=['aqua','terr'],\n",
    "  data_type=\"f\",\n",
    "  start_chain=26,\n",
    "  end_chain=26\n",
    ").to_csv('discr/discr_2end_c26.csv', index=False)\n",
    "\n",
    "discr_2end_c28 = make_discr(\n",
    "  source_names=['aqua','terr'],\n",
    "  data_type=\"f\",\n",
    "  start_chain=28,\n",
    "  end_chain=28\n",
    ").to_csv('discr/discr_2end_c28.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "plaintext"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
